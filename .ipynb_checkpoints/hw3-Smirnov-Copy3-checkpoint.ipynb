{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdGytgToeb3D"
   },
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HplY4Ppeb3F"
   },
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 27 апреля 2020, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 27 апреля, -4 балла после 08:30 4 мая, -6 баллов после 08:30 11 мая, -8 баллов после 08:30 18 мая.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0220, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LrxmDNMQeb3G"
   },
   "source": [
    "##  Реализуем дерево решений (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBQELacFeb3H"
   },
   "source": [
    "Допишите недостающие части дерева решений. Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn.\n",
    "Внимание: если Вас не устраивает предложенная структура хранения дерева, Вы без потери баллов можете сделать свой класс DecisionTreeClassifier, в котором сами полностью воспроизведете алгоритм дерева решений. Обязательно в нем иметь только функции fit, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_CWdGMKeb3I"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, node_type, feature_id=None, threshold=None, class_id=None, probability=None):\n",
    "        \"\"\"\n",
    "        Иниициализация узла дерева\n",
    "        \"\"\"\n",
    "        self.node_type = node_type\n",
    "        if node_type:\n",
    "            self.feature_id = feature_id\n",
    "            self.threshold = threshold\n",
    "        else:\n",
    "            self.class_id = class_id\n",
    "            self.probability = probability\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  def __info(self, l_c, l_s, r_c, r_s, criterion):\n",
    "#         \"\"\"\n",
    "#         Считаем меру неопределённости\n",
    "#         посредством критерия criterion\n",
    "#         по выборке (x, y)\n",
    "#         \"\"\"\n",
    "\n",
    "#         if   criterion == 'misclass':\n",
    "#             return self.__misclass(l_c, l_s, r_c, r_s)\n",
    "        \n",
    "#         elif criterion == 'gini':\n",
    "#             return self.__gini(l_c, l_s, r_c, r_s)\n",
    "        \n",
    "#         elif criterion == 'entropy':\n",
    "#             return self.__entropy(l_c, l_s, r_c, r_s)\n",
    "        \n",
    "#         else:\n",
    "#             raise RuntimeError(\"No such criterion as \\'{}\\'!\".format(criterion))\n",
    "\n",
    "            \n",
    "            \n",
    "#     def __gini(self, l_c, l_s, r_c, r_s):#матрицы: NxKxF. N - число объектов\n",
    "#         l_s = l_s.astype('float')  # K - число классов, F - число признаков. r_c - общее количество \n",
    "#         r_s = r_s.astype('float')  # справа, r_s количество справа по классам.\n",
    "#                                    # l_s: l_s - r_s = количество объектов слева по классам\n",
    "#                                    # l_c: l_c - r_c = общее количество объектов слева\n",
    "#         return ((r_s-l_s*(r_c/l_c))**2).sum(axis=1)/((l_c-r_c)*r_c).reshape(-1,1)\n",
    "    \n",
    "#     def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "#         return reduce(lambda ans,x:ans+(x[0]*np.log(x[0]/x[1]+0.000000000001)).sum(axis=1),\n",
    "#                       [[l_s-r_s,l_c-r_c],[r_s,r_c],[-l_s,-l_c]],0)/l_c\n",
    "#     def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "#         return ((l_s-r_s)/(l_c-r_c)).max(axis=1)+(r_s/r_c).max(axis=1)-(l_s/l_c).max(axis=1)\n",
    "\n",
    "#     def __find_threshold(self, x, y):\n",
    "#         y_un=np.unique(y)\n",
    "#         LS=(y[...,np.newaxis]==y_un[np.newaxis]).sum(axis=0)\n",
    "#         if LS.max()==y.shape[0]:\n",
    "#             return [-1,-1]\n",
    "        \n",
    "#         best_gain=0\n",
    "#         best_feature=best_th=-1\n",
    "        \n",
    "#         rc=np.arange(1,y.shape[0])\n",
    "        \n",
    "#         Y=y.shape[0]\n",
    "        \n",
    "#         feature_ids=np.arange(x.shape[1])\n",
    "#         sorted_ids=x[:,feature_ids].argsort(axis=0)\n",
    "#         rs=(y[sorted_ids][:,np.newaxis]==y_un[np.newaxis,:,np.newaxis]).astype(int)\n",
    "#         for i in range(1,y.shape[0]):\n",
    "#                 rs[i]+=rs[i-1]\n",
    "#         R=rs[-1]\n",
    "#         rs=rs[:-1]\n",
    "#         gain=self.__info(Y,R[np.newaxis],rc[...,np.newaxis,np.newaxis],rs, self.criterion)\n",
    "#         r=np.take_along_axis(x,sorted_ids,axis=0)\n",
    "#         gain*=r[:-1]!=r[1:]\n",
    "#         best_idx=gain.argmax()\n",
    "#         if gain.ravel()[best_idx] > 0:\n",
    "#             best_feature=feature_ids[best_idx%gain.shape[1]]\n",
    "#             best_th=x[sorted_ids.ravel()[best_idx],best_feature]\n",
    "# #             self.feature_importances_[best_feature] += gain.ravel()[best_idx]\n",
    "    \n",
    "#         return best_feature,best_th\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "#     def __find_threshold(self, x, y):\n",
    "#         \"\"\"\n",
    "#         Находим оптимальный признак и порог для сплита\n",
    "#         Здесь используемые разные impurity в зависимости от self.criterion\n",
    "#         \"\"\"\n",
    "#         best_threshold = None\n",
    "# #         print('ok')\n",
    "#         for i in range(x.shape[1]):\n",
    "#             x_sorted = np.sort(x[:,i])\n",
    "#             y_sorted = y[np.argsort(x[:,i])]\n",
    "#             y_shifted = np.roll(y_sorted, -1)\n",
    "#             y_shifted[-1] = y_sorted[-1]\n",
    "# #             y_shifted[0] = y_sorted[0]\n",
    "# #             print(y_sorted, y_shifted)\n",
    "#             indexes = np.where(y_sorted != y_shifted)[0]\n",
    "# #             print(indexes)\n",
    "#             if np.unique(x_sorted).shape[0] > 1:\n",
    "#                 thresholds_low = x_sorted[indexes]\n",
    "#                 thresholds_high = x_sorted[indexes+1]\n",
    "#                 thresholds = (thresholds_low + thresholds_high)/2\n",
    "# #                 print('thresholds = ',thresholds)\n",
    "# #             print(i, thresholds)\n",
    "#                 res = list(map(lambda t: self.functional(x, y, i, t), thresholds))\n",
    "# #                 print('functional = ',res)\n",
    "# #                 print('x = ', x_sorted)\n",
    "# #             print(max(res))\n",
    "#                 threshold = thresholds[np.argmax(res)]\n",
    "#                 if best_threshold == None or threshold > best_threshold:\n",
    "#                     best_threshold = threshold\n",
    "#                     feature_id = i\n",
    "#         return feature_id, best_threshold\n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "#     def __find_threshold(self, x, y):\n",
    "#         \"\"\"\n",
    "#         Находим оптимальный признак и порог для сплита\n",
    "#         Здесь используемые разные impurity в зависимости от self.criterion\n",
    "#         \"\"\"\n",
    "#         best_threshold = None\n",
    "# #         print('ok')\n",
    "# #         for i in range(x.shape[1]):\n",
    "#         i = np.arange(x.shape[1])\n",
    "    \n",
    "#         x_sorted = np.sort(x[:,i], axis=0)\n",
    "#         y_sorted = y[np.argsort(x[:,i], axis=0)]\n",
    "#         y_shifted = np.roll(y_sorted, -1)\n",
    "#         y_shifted[-1] = y_sorted[-1]\n",
    "# #             y_shifted[0] = y_sorted[0]\n",
    "# #             print(y_sorted, y_shifted)\n",
    "#         indexes = np.where(y_sorted != y_shifted)[0]\n",
    "#         if np.unique(x_sorted).shape[0] > 1:\n",
    "#             thresholds_low = x_sorted[indexes]\n",
    "#             thresholds_high = x_sorted[indexes+1]\n",
    "#             thresholds = (thresholds_low + thresholds_high)/2\n",
    "#             print('thresholds = ',thresholds)\n",
    "# #                 thresholds = x_sorted + 0.00000001\n",
    "# #             print(i, thresholds)\n",
    "#             res = list(map(lambda t: self.functional(x, y, i, t), thres))\n",
    "# #                 print('functional = ',res)\n",
    "# #                 print('x = ', x_sorted)\n",
    "# #             print(max(res))\n",
    "#             threshold = thresholds[np.argmax(res)]\n",
    "#             if best_threshold == None or threshold > best_threshold:\n",
    "#                 best_threshold = threshold\n",
    "#                 feature_id = i\n",
    "#         return feature_id, best_threshold\n",
    "#         # Ваш код здесь\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  daves\n",
    "\n",
    "#     def __info(self, l_c, l_s, r_c, r_s, criterion):\n",
    "#         \"\"\"\n",
    "#         Считаем меру неопределённости\n",
    "#         посредством критерия criterion\n",
    "#         по выборке (x, y)\n",
    "#         \"\"\"\n",
    "\n",
    "#         if   criterion == 'misclass':\n",
    "#             return self.__misclass(l_c, l_s, r_c, r_s)\n",
    "        \n",
    "#         elif criterion == 'gini':\n",
    "#             return self.__gini(l_c, l_s, r_c, r_s)\n",
    "        \n",
    "#         elif criterion == 'entropy':\n",
    "#             return self.__entropy(l_c, l_s, r_c, r_s)\n",
    "        \n",
    "#         else:\n",
    "#             raise RuntimeError(\"No such criterion as \\'{}\\'!\".format(criterion))\n",
    "\n",
    "            \n",
    "            \n",
    "#     def __gini(self, l_c, l_s, r_c, r_s):#матрицы: NxKxF. N - число объектов\n",
    "#         l_s = l_s.astype('float')  # K - число классов, F - число признаков. r_c - общее количество \n",
    "#         r_s = r_s.astype('float')  # справа, r_s количество справа по классам.\n",
    "#                                    # l_s: l_s - r_s = количество объектов слева по классам\n",
    "#                                    # l_c: l_c - r_c = общее количество объектов слева\n",
    "#         return ((r_s-l_s*(r_c/l_c))**2).sum(axis=1)/((l_c-r_c)*r_c).reshape(-1,1)\n",
    "    \n",
    "#     def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "#         return reduce(lambda ans,x:ans+(x[0]*np.log(x[0]/x[1]+0.000000000001)).sum(axis=1),\n",
    "#                       [[l_s-r_s,l_c-r_c],[r_s,r_c],[-l_s,-l_c]],0)/l_c\n",
    "#     def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "#         return ((l_s-r_s)/(l_c-r_c)).max(axis=1)+(r_s/r_c).max(axis=1)-(l_s/l_c).max(axis=1)\n",
    "\n",
    "#     def __find_threshold(self, x, y):\n",
    "#         y_un=np.unique(y)\n",
    "#         LS=(y[...,np.newaxis]==y_un[np.newaxis]).sum(axis=0)\n",
    "#         if LS.max()==y.shape[0]:\n",
    "#             return [-1,-1]\n",
    "        \n",
    "#         best_gain=0\n",
    "#         best_feature=best_th=-1\n",
    "        \n",
    "#         rc=np.arange(1,y.shape[0])\n",
    "        \n",
    "#         Y=y.shape[0]\n",
    "        \n",
    "#         feature_ids=np.arange(x.shape[1])\n",
    "#         sorted_ids=x[:,feature_ids].argsort(axis=0)\n",
    "#         rs=(y[sorted_ids][:,np.newaxis]==y_un[np.newaxis,:,np.newaxis]).astype(int)\n",
    "#         for i in range(1,y.shape[0]):\n",
    "#                 rs[i]+=rs[i-1]\n",
    "#         R=rs[-1]\n",
    "#         rs=rs[:-1]\n",
    "#         gain=self.__info(Y,R[np.newaxis],rc[...,np.newaxis,np.newaxis],rs, self.criterion)\n",
    "#         print('x = ', x)\n",
    "#         print('y = ', y)\n",
    "#         print('Y = ', Y)\n",
    "#         print('R[np.newaxis] = ', R[np.newaxis])\n",
    "#         print('rc[...,np.newaxis,np.newaxis] = ',rc[...,np.newaxis,np.newaxis])\n",
    "#         print('rs = ',rs)\n",
    "#         print('info = ', gain)\n",
    "#         r=np.take_along_axis(x,sorted_ids,axis=0)\n",
    "#         gain*=r[:-1]!=r[1:]\n",
    "#         best_idx=gain.argmax()\n",
    "#         if gain.ravel()[best_idx] > 0:\n",
    "#             best_feature=feature_ids[best_idx%gain.shape[1]]\n",
    "#             best_th=x[sorted_ids.ravel()[best_idx],best_feature]\n",
    "# #             self.feature_importances_[best_feature] += gain.ravel()[best_idx]\n",
    "    \n",
    "#         return best_feature,best_th\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "\n",
    "def proportion(y, class_id=None):\n",
    "    classes, counts = np.unique(y, return_counts=True) \n",
    "#     print(classes, counts)\n",
    "#     print((counts[np.where(classes == class_id)]/len(y))[0])\n",
    "    print(counts/counts.sum()*(1-counts/counts.sum()))\n",
    "#     return (counts[np.where(classes == class_id)]/len(y))[0]\n",
    "def max_dole(y):\n",
    "#     print(y)\n",
    "#     print(proportion(y, 2))\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    return classes[np.argmax(counts)]\n",
    "    doles = y[np.argmax(list(map(lambda class_id: proportion(y, class_id),np.unique(y))))]\n",
    "#     print(doles)\n",
    "#     return y[np.where(np.asarray([proportion(y, class_id) for class_id in np.unique(y)]).max() == y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24   0.2275 0.1875]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "y = [0, 0, 0, 1, 1, 1, 1, 0, 0, 2, 0, 2, 2, 1, 1, 2, 0, 1, 0, 2]\n",
    "# print(np.asarray([proportion(y, class_id) for class_id in np.unique(y)]).max())\n",
    "print(proportion(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 4]\n",
      " [1 0 4 4]\n",
      " [2 3 1 2]\n",
      " [1 1 1 4]]\n",
      "[[1 0 0 2]\n",
      " [1 0 1 4]\n",
      " [2 1 1 4]\n",
      " [2 3 4 4]]\n",
      "\n",
      "[[1 0 0 2]\n",
      " [1 0 1 4]\n",
      " [2 1 1 4]]\n",
      "\n",
      "[[1 0 1 4]\n",
      " [2 1 1 4]\n",
      " [2 3 4 4]]\n",
      "[[1.  1.5 2.  0. ]\n",
      " [0.  0.5 2.  1. ]\n",
      " [0.5 1.  2.5 2. ]\n",
      " [3.  4.  4.  3. ]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[2, 0, 0, 4], [1, 0, 4, 4], [2, 3, 1, 2], [1, 1, 1, 4]])\n",
    "# a = np.array([[1,0,1]])\n",
    "print(a)\n",
    "a = np.sort(a, axis=0)\n",
    "print(a)\n",
    "print()\n",
    "# b = np.roll(a, -1, axis=0)\n",
    "b = a[1:]\n",
    "a = a[:-1]\n",
    "print(a)\n",
    "print()\n",
    "print(b)\n",
    "\n",
    "c = ((a+b)/2).T\n",
    "d = np.arange(c.shape[0])\n",
    "# print(np.concatenate((c,d), axis = 1))\n",
    "print(np.column_stack((c,d)))\n",
    "# c = c[:-1].T\n",
    "# print()\n",
    "# print(c.T)\n",
    "# print(c)\n",
    "# print(np.hstack((c, np.arange(c.shape[0])[:,np.newaxis])))\n",
    "# print(np.index(c[0]))\n",
    "# x_sorted = np.sort(x[:,i], axis=0)\n",
    "#         y_sorted = y[np.argsort(x[:,i], axis=0)]\n",
    "#         y_shifted = np.roll(y_sorted, -1)\n",
    "#         y_shifted[-1] = y_sorted[-1]\n",
    "# #             y_shifted[0] = y_sorted[0]\n",
    "# #             print(y_sorted, y_shifted)\n",
    "#         indexes = np.where(y_sorted != y_shifted)[0]\n",
    "#         if np.unique(x_sorted).shape[0] > 1:\n",
    "#             thresholds_low = x_sorted[indexes]\n",
    "#             thresholds_high = x_sorted[indexes+1]\n",
    "#             thresholds = (thresholds_low + thresholds_high)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "new = np.concatenate((c,d), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "new2 = np.hstack((c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 8.82 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "new3= np.column_stack((c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 4]\n",
      " [1 0 4 4]\n",
      " [2 3 1 3]]\n",
      "[[2 1 2]\n",
      " [0 0 3]\n",
      " [0 4 1]\n",
      " [4 4 3]]\n",
      "[[0 0 2 4]\n",
      " [0 4 1 4]\n",
      " [3 1 2 3]]\n",
      "(3, 4)\n",
      "[[2 0 0 4]\n",
      " [1 0 4 4]\n",
      " [2 3 1 3]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "wrong number of positional arguments: expected 2, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-81471c5911b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mvfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'(n),(n)->(),()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m# b = np.array([[2, 0, 0, 4], [1, 0, 4, 4], [2, 3, 1, 3], [1, 1, 1, 2], [3, 4, 5, 3], [1, 2, 3, 4]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# c = np.arange(6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sphere-py37/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sphere-py37/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2155\u001b[0m         \u001b[0;34m\"\"\"Vectorized call to `func` over positional `args`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call_with_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sphere-py37/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call_with_signature\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2181\u001b[0m             raise TypeError('wrong number of positional arguments: '\n\u001b[1;32m   2182\u001b[0m                             \u001b[0;34m'expected %r, got %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2183\u001b[0;31m                             % (len(input_core_dims), len(args)))\n\u001b[0m\u001b[1;32m   2184\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: wrong number of positional arguments: expected 2, got 1"
     ]
    }
   ],
   "source": [
    "a = np.array([[2, 0, 0, 4], [1, 0, 4, 4], [2, 3, 1, 3]])\n",
    "# print(type(next((map(lambda i: np.unique(a[:,i]), range(a.shape[1]))))))\n",
    "# b = list(map(lambda i: np.unique(a[:,i]) , range(a.shape[1])))\n",
    "print(a)\n",
    "print(a.T)\n",
    "print(np.unique(a, axis=1))\n",
    "print(a.shape)\n",
    "\n",
    "print(a)\n",
    "# b = enumerate(a)\n",
    "# c = *b\n",
    "# print(c)\n",
    "\n",
    "# res = np.apply_along_axis(lambda x: test(x), axis=0, arr=a.T)\n",
    "# print(np.fromiter(np.ndenumerate(a),dtype=np.narray))\n",
    "# print(np.apply_along_axis(lambda c: (np.unique(c), axis=1, arr=a.T))\n",
    "\n",
    "def test(b):\n",
    "    if not hasattr(test, 'counter'):\n",
    "        setattr(test, 'counter', 0)\n",
    "    print(b)\n",
    "    res = (test.counter, np.unique(b))\n",
    "    test.counter += 1\n",
    "    return res\n",
    "\n",
    "vfunc = np.vectorize(test, signature='(n),(n)->(),()')\n",
    "\n",
    "print(vfunc(a.T))\n",
    "# b = np.array([[2, 0, 0, 4], [1, 0, 4, 4], [2, 3, 1, 3], [1, 1, 1, 2], [3, 4, 5, 3], [1, 2, 3, 4]])\n",
    "# c = np.arange(6)\n",
    "# print(c)\n",
    "# np.random.seed(seed=0)\n",
    "# np.random.shuffle([b,c])\n",
    "# # np.random.shuffle(c)\n",
    "# print(b, c)\n",
    "# c = [[], [2, 2], [3, 4]]\n",
    "\n",
    "# c = np.asarray(list(enumerate(c)))\n",
    "# print(c)\n",
    "# print(c[:,1])\n",
    "# c[(len(c)==0)]=np.inf\n",
    "# list(filter(, c[:,1]))\n",
    "# print(np.where(c[:,1].shape[0] != 0))\n",
    "# info = c[np.where(c[:,1].shape[0] != 0)]\n",
    "# print(info)\n",
    "\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 10  3 11  2 12  1 13  0 14  9  8  7  6  5]\n",
      "[ 1  1  2  2  3  3  4  4  5  5  6  7  8  9 10]\n",
      "[0, 0, 0, 0, 2, 2, 0, 0, 1, 1, 2, 0, 0, 2, 1]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x=[5,4,3,2,1,10,9,8,7,6,1,2,3,4,5]\n",
    "y=[1,0,2,0,0,1,2,0,0,2,0,0,2,0,1]\n",
    "x_sorted = np.sort(x)\n",
    "y_sorted = list([y[i] for i in np.argsort(x)])\n",
    "index = np.argsort(x)\n",
    "print(index)\n",
    "print(x_sorted)\n",
    "print(y_sorted)\n",
    "x=[1,1,1,2]\n",
    "print(np.unique(x).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion_all(y):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "    return counts/np.sum(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 8.11 µs\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "for i in range(10000):\n",
    "    class_id = stats.mode(y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "for i in range(10000):\n",
    "    class_id = proportion_all(y)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jaljC28eb3O"
   },
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier():\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=3, criterion='gini'):\n",
    "        \"\"\"\n",
    "        criterion -- критерий расщепления. необходимо релизовать три:\n",
    "        Ошибка классификации, Индекс Джини, Энтропийный критерий\n",
    "        max_depth -- максимальная глубина дерева\n",
    "        min_samples_split -- минимальное число объектов в листе, чтобы сделать новый сплит\n",
    "        \"\"\"\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.num_class = -1\n",
    "        # Для последнего задания\n",
    "        self.feature_importances_ = None\n",
    "        self.criterion = criterion\n",
    "        # Структура, которая описывает дерево\n",
    "        # Представляет словарь, где для  node_id (айдишник узла дерева) храним\n",
    "        # (тип_узла, айдишник признака сплита, порог сплита) если тип NON_LEAF_TYPE\n",
    "        # (тип_узла/, предсказание класса, вероятность класса) если тип LEAF_TYPE\n",
    "        # Подразумевается, что у каждого node_id в дереве слева \n",
    "        # узел с айди 2 * node_id + 1, а справа 2 * node_id + 2\n",
    "        self.tree_ = dict()\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        \"\"\"\n",
    "        Разделяет объекты на 2 множества\n",
    "        x -- матрица объектов\n",
    "        y -- вектор ответов\n",
    "        feature_id -- айдишник признака, по которому делаем сплит\n",
    "        threshold -- порог, по которому делаем сплит\n",
    "        \"\"\"\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def proportion(self, y, class_id=None):\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        return (counts[np.where(classes == class_id)]/np.sum(counts))\n",
    "        \n",
    "    def proportion_all(self, y):\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        return counts/np.sum(counts)\n",
    "        \n",
    "    def max_dole(self, y):\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "#         return classes[np.argmax(counts)]\n",
    "        return np.max(counts)/np.sum(counts)\n",
    "\n",
    "    def functional(self, x, y, feature_id, t):\n",
    "#         print(feature_id, t)\n",
    "        x_left, x_right, y_left, y_right = self.__div_samples(x, y, feature_id, t)\n",
    "#         print(x,x_left, x_right)\n",
    "#         return  y_left.shape[0]/y.shape[0]*self.H(y_left) + y_right.shape[0]/y.shape[0]*self.H(y_right)\n",
    "        return  y_left.size/y.size*self.H(y_left) + y_right.size/y.size*self.H(y_right)\n",
    "\n",
    "\n",
    "    def best_feature_threshold(self, info, x, y):\n",
    "        feature_id = np.int(info[0])\n",
    "        thresholds = info[1:]\n",
    "#         print('info = ',info)\n",
    "        res = np.apply_along_axis(lambda t: self.functional(x, y, feature_id, t[0]), axis=1, arr=thresholds[:, np.newaxis])\n",
    "#         res = np.apply_along_axis(lambda t: self.functional(x, y, feature_id, t), axis=0, arr=thresholds)\n",
    "        threshold = thresholds[np.argmin(res)]\n",
    "#         threshold = thresholds[np.argmax(res)]\n",
    "#         print('feature_id = ', feature_id, 'res = ', np.max(res))\n",
    "        return (threshold, np.min(res))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def H(self, y):\n",
    "        \n",
    "        if self.criterion == 'errorclass':\n",
    "            return 1 - self.max_dole(y)\n",
    "        \n",
    "        elif self.criterion == 'gini':\n",
    "            res = self.proportion_all(y)\n",
    "            return (res*(1 - res)).sum()\n",
    "        \n",
    "        elif self.criterion == 'entropy':\n",
    "            res = self.proportion_all(y)\n",
    "            return -(res*np.log(res)).sum()\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        \"\"\"\n",
    "        Находим оптимальный признак и порог для сплита\n",
    "        Здесь используемые разные impurity в зависимости от self.criterion\n",
    "        \"\"\"\n",
    "        best_threshold = None\n",
    "        feature_id = 0\n",
    "        if (x.shape[0] > 15):\n",
    "            x, y = shuffle(x, y, random_state=0)\n",
    "            length = np.int(np.sqrt(x.shape[0])-1)\n",
    "#             length = np.int((x.shape[0])/2)\n",
    "            x, y = x[:length], y[:length]\n",
    "        if (x.shape[0] > 1):\n",
    "\n",
    "            x_sorted = np.sort(x, axis=0)\n",
    "    #         print(x)\n",
    "#             x_shifted = np.roll(x_sorted, -1, axis=0)\n",
    "            x_shifted = x_sorted[1:]\n",
    "            x_sorted = x_sorted[:-1]\n",
    "    #         print(b)\n",
    "            thresholds = ((x_sorted + x_shifted)/2).T\n",
    "            info = np.column_stack((np.arange(thresholds.shape[0]),thresholds))\n",
    "#             info = np.concatenate((np.arange(thresholds.shape[0])[:,np.newaxis], thresholds), axis = 1)\n",
    "#             info = np.hstack((np.arange(thresholds.shape[0])[:,np.newaxis], thresholds))\n",
    "#             info = np.asarray(list(enumerate(thresholds)))\n",
    "#             print(info)\n",
    "\n",
    "    #         info = info[np.where(info[:,1]!=[])]\n",
    "#             res = np.apply_along_axis(lambda single_info: self.best_feature_threshold(x, y, single_info), axis=1, arr=info)\n",
    "            res = np.apply_along_axis(self.best_feature_threshold, 1, info, x, y)\n",
    "    #         print('!!!!!!!!! res = ', res)\n",
    "            funcs = res[:, 1]\n",
    "    #         best_threshold = np.max(res)\n",
    "            feature_id = np.argmin(funcs)\n",
    "            best_threshold = res[feature_id, 0]\n",
    "#         feature_id = np.where(res == best_threshold)[0][0]\n",
    "        \n",
    "        return feature_id, best_threshold\n",
    "    \n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        \"\"\"\n",
    "        Делаем новый узел в дереве\n",
    "        Решаем, терминальный он или нет\n",
    "        Если нет, то строим левый узел  с айди 2 * node_id + 1\n",
    "        И правый узел с  айди 2 * node_id + 2\n",
    "        \"\"\"\n",
    "        if self.max_depth <= depth or self.min_samples_split > x.shape[0]:# or same_class == 1:\n",
    "            \n",
    "            class_id = stats.mode(y)[0]\n",
    "            probability = self.proportion(y, class_id)\n",
    "            self.tree_[node_id] = (self.LEAF_TYPE, class_id, probability)    \n",
    "    \n",
    "        else:\n",
    "            \n",
    "            feature_id, threshold = self.__find_threshold(x, y)\n",
    "            self.tree_[node_id] = (self.NON_LEAF_TYPE, feature_id, threshold) \n",
    "#             print('feature_id = ', feature_id, 'threshold = ', threshold)\n",
    "            x_left, x_right, y_left, y_right = self.__div_samples(x, y, feature_id, threshold)\n",
    "\n",
    "            self.__fit_node(x_left, y_left, 2*node_id + 1, depth + 1)\n",
    "            self.__fit_node(x_right, y_right, 2*node_id + 2, depth + 1)\n",
    "            \n",
    "        # Ваш код здесь\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Рекурсивно строим дерево решений\n",
    "        Начинаем с корня node_id 0\n",
    "        \"\"\"\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        \"\"\"\n",
    "        Рекурсивно обходим дерево по всем узлам,\n",
    "        пока не дойдем до терминального\n",
    "        \"\"\"\n",
    "        node = self.tree_[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Вызывает predict для всех объектов из матрицы X\n",
    "        \"\"\"\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "    \n",
    "    def get_feature_importance():\n",
    "        \"\"\"\n",
    "        Возвращает важность признаков\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5dct_Jmyeb3S"
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, criterion='gini')\n",
    "clf = DecisionTreeClassifier(min_samples_split=2, criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZ5th7Q_eb3V",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)\n",
    "my_clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-38c66fc17680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'images/clf_tree.doyut'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images/clf_tree.dot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "from graphviz import Source\n",
    "from IPython.display import SVG\n",
    "# graph = Source(tree.export_graphviz(clf, out_file = None))\n",
    "tree.export_graphviz(clf, out_file='images/clf_tree.doyut')\n",
    "Source.from_file('images/clf_tree.dot')\n",
    "SVG(graph.pipe(format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 2 0 0 0 0 0 0 0 1 1 0 2 1 2 0] [1 1 2 2 2 0 0 0 0 1 0 1 1 0 2 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred=my_clf.predict(X_test)\n",
    "print(y_pred[:,0], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaJMB0nteb3Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SS17uSMLeb3c"
   },
   "source": [
    "## Ускоряем дерево решений (2 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine. \n",
    "Для этого используем numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSmcHPJqeb3d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.62 ms, sys: 1.57 ms, total: 4.19 ms\n",
      "Wall time: 2.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUnzsxQ0eb3g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 69.7 ms, sys: 8.03 ms, total: 77.7 ms\n",
      "Wall time: 70.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAvnppm3eb3i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JsDCB7bZeb3l"
   },
   "source": [
    "## Боевое применение (3 балла)\n",
    "\n",
    "На практике Вы познакомились с датасетом Speed Dating Data. В нем каждая пара в быстрых свиданиях характеризуется определенным набором признаков. Задача -- предсказать, произойдет ли матч пары (колонка match). \n",
    "\n",
    "Пример работы с датасетом можете найти в практике пункт 2\n",
    "https://github.com/VVVikulin/ml1.sphere/blob/master/2019-09/lecture_06/pract-trees.ipynb\n",
    "\n",
    "Данные и описания колонок лежат тут\n",
    "https://cloud.mail.ru/public/8nHV/p6J7wY1y1/speed-dating-experiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPXih1UWeb3l"
   },
   "source": [
    "Скачайте датасет, обработайте данные, как показано на семинаре или своим собственным способом. Обучите дерево классифкации. В качестве таргета возьмите колонку 'match'. Постарайтесь хорошо обработать признаки, чтобы выбить максимальную точность. Если точность будет близка к случайному гаданию, задание не будет защитано. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8KrRNWceb3l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iw_SuXkTeb3n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CSlooy9qeb3p"
   },
   "source": [
    "Разбейте датасет на трейн и валидацию. Подберите на валидации оптимальный критерий  информативности. \n",
    "Постройте графики зависимости точности на валидации от глубины дерева, от минимального числа объектов для сплита. \n",
    "Какой максимальной точности удалось достигнуть?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRaAo9ZKeb3q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0C78Xs4eb3s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "npwT3a2leb3t"
   },
   "source": [
    "## Находим самые важные признаки (2 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6TQ3s2Zeb3u"
   },
   "source": [
    "По построенному дереву  легко понять, какие признаки лучше всего помогли решить задачу. Часто это бывает нужно  не только  для сокращения размерности в данных, но и для лучшего понимания прикладной задачи. Например, Вы хотите понять, какие признаки стоит еще конструировать -- для этого нужно понимать, какие из текущих лучше всего работают в дереве. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Shq0alwqeb3u"
   },
   "source": [
    "Самый простой метод -- посчитать число сплитов, где использовался данные признак. Это не лучший вариант, так как по признаку который принимает всего 2 значения, но который почти точно разделяет выборку, число сплитов будет очень 1, но при этом признак сам очень хороший. \n",
    "В этом задании предлагается для каждого признака считать суммарный gain (в лекции обозначено как Q) при использовании этого признака в сплите. Тогда даже у очень хороших признаков с маленьким число сплитов это значение должно быть довольно высоким.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ROd0xVzeb3u"
   },
   "source": [
    "Реализовать это довольно просто: создаете словарь номер фичи : суммарный гейн и добавляете в нужную фичу каждый раз, когда используете ее при построении дерева. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9gCeM_Uleb3v"
   },
   "source": [
    "Добавьте функционал, который определяет значения feature importance. Обучите дерево на датасете Speed Dating Data.\n",
    "Выведите 10 главных фичей по важности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oI-HVGqSeb3v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pk-PFu9-eb3w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G6vINKJieb3x"
   },
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoKb-nRFeb3y"
   },
   "source": [
    "* Какие аспекты обучения деревьев решений Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-jnGTLLueb3y"
   },
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IAsSXijGeb3y"
   },
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1VJdZLAteb3y"
   },
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VCak6tdteb3z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsumvyFPeb30"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "hw3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
